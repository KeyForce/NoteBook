## 背景

目前来说，目标检测都是在fit数据集，从数据集的角度来说，太过依赖数据集的标注质量会导致卷积神经网络的泛化性能；针对el图像，同样一幅图中可能存在大量相似的缺陷，这些缺陷细长，量多，标注的成本很高，单单从representation learning的角度，这个缺陷的特征是及其相似的domain-invariant feature

## 问题

## 方法部分（核心的公式，定义，图）

Easy-to-Hard 迁移策略 利用跨模态相似度逐步选择可靠的伪标签

【ECCV 2020】Suppressing Mislabeled Data via Grouping and Self-Attention，通过分组和自注意力机制来抑制错误标签

　Instance reweighting和subspace learning是Domain adaptation中两种经典的学习策略前者对source data每一个样本加权，学习一组权使得分布差异最小化，后者则是转换到一个新的共享样本空间上，使得两者的分布相匹配。另外比较重要的的一点是，实际训练当中，“最小化分布差异”这个约束条件是放在目标函数中和最小化误差一起优化的，而不是单独优化。

[【算法笔记】域适应（Domain Adaptation）_nymph_h的博客-CSDN博客](https://blog.csdn.net/nymph_h/article/details/96424172?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-13.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-13.control)

[2020 Domain Adaptation 最新论文：插图速览（三）_u014546828的博客-CSDN博客](https://blog.csdn.net/u014546828/article/details/110385554?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-16.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-16.control)



[(99+ 封私信 / 80 条消息) FeatMatch - 搜索结果 - 知乎](https://www.zhihu.com/search?type=content&q=FeatMatch)

半监督图像分类任务有两大核心方法：一致性正则（**Consistency Regularization**）和打伪标签法（**Pseudo-Label**）

