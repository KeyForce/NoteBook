# 数据增强

- Mixup：将随机的两张样本按比例混合，分类的结果按比例分配；
- Cutout：随机的将样本中的部分区域cut掉，并且填充0像素值，分类的结果不变；
- CutMix：就是将一部分区域cut掉但不填充0像素而是随机填充训练集中的其他数据的区域像素值，分类结果按一定的比例分配
- Mosaic：将四张图片随机缩放后拼接在一起构成一张训练的图片
- Color Jittering：对颜色的数据增强：图像亮度、饱和度、对比度变化
- Random Scale：尺度变换
- Random Crop：采用随机图像差值方式，对图像进行裁剪、缩放
- Horizontal/Vertical Flip：水平/垂直翻转
- Shift：平移变换
- Rotation/Reflection：旋转/仿射变换

# 网络结构

## FPN的结构

特征金字塔网络 Feature Pyramid Networks

**顶层特征通过上采样（最近邻插值）和底层特征做融合**，而且每层都是独立预测的（足够底层的特征对于检测小物体是很有帮助的）

![img](image/v2-3af297d1950b57041f45658371779489_b.jpg)

**算法大致结构**

**一个自底向上的线路，一个自顶向下的线路，横向连接（lateral connection）**。图中放大的区域就是横向连接，这里1*1的卷积核的主要作用是减少卷积核的个数，也就是减少了feature map的个数，并不改变feature map的尺寸大小。

**基于FPN的RPN是怎么训练的**

在FPN的每个融合后特征图的每一层上都接一个RPN子网（3*3卷积和2个并列的1\*1卷积），确定RPN子网的正负anchor box样本，再计算各预测层上RPN的anchor box分类和回归损失。

# 激活函数

## ReLu

<img src="../../../Main Project/Computer-Vison/NoteBook/image/v2-886da65a9f27b8b0952fa1a4d3e26c38_b.jpg" alt="img" style="zoom:150%;" />

## Leaky ReLU

<img src="../../../Main Project/Computer-Vison/NoteBook/image/v2-7f22822e188109523570ebf9e8de5e4e_b.jpg" alt="img" style="zoom:150%;" />

## Mish-Activation

`Mish=x * tanh(ln(1+e^x)) `

![640?wx_fmt=jpeg](image/p)



# 损失函数

## 1.Dice Loss 医学影像分割

# 语义分割

## 1.FCN

FCN 的思想很直观，即直接进行像素级别端到端（end-to-end）的语义分割，它可以基于主流的深度卷积神经网络模型（CNN）来实现。正所谓‘全卷积神经网络‘，在FCN中，传统的全连接层 fc6 和 fc7 均是由卷积层实现，而最后的 fc8 层则被替代为一个 **21 通道**（channel）的 1x1 卷积层，作为网络的最终输出。之所以有 21 个通道是因为 PASCAL VOC 的数据中包含 21 个类别（20个「object」类别和一个「background」类别）



下图为 FCN 的网络结构，若原图为 H×W×3，在经过若干堆叠的卷积和池化层操作后可以得到原图对应的响应张量（Activation tensor）[![clip_image001](image/1139079-20170621162544007-233703012.png)](http://images2015.cnblogs.com/blog/1139079/201706/1139079-20170621162543570-1328652783.png) ，其中，[![clip_image002](image/1139079-20170621162544866-658506214.png)](http://images2015.cnblogs.com/blog/1139079/201706/1139079-20170621162544585-1672214780.png) 为 i 第 层的通道数。可以发现，**由于池化层的下采样作用，使得响应张量的长和宽远小于原图的长和宽，这便给像素级别的直接训练带来问题**。



为了解决下采样带来的问题，**FCN 利用双线性插值将响应张量的长宽上采样到原图大小**，另外为了更好的预测图像中的细节部分，**FCN 还将网络中浅层的响应也考虑进来**。具体来说，就是将 Pool4 和 Pool3 的响应也拿来，分别作为模型 FCN-16s 和 FCN-8s 的输出，与原来 FCN-32s 的输出结合在一起做最终的语义分割预测（如下图所示）。

![image](image/1139079-20170621163041476-975958559-1591795835570.png)

![image](image/1139079-20170621163041882-328871918.png)

**影响语言分割的像素精度的主要原因是池化层的下采样操作**，由下图可以看出FCN-32s使用FCN 的最后一层卷积和池化的输出，该模型的下采样倍数最高，其对应的语义分割结果最为粗略；而 FCN-8s 则因下采样倍数较小可以取得较为精细的分割结果。

![image](image/1139079-20170621163044570-1438981130-1567156775830.png)

## 2.deeplab v3+相比于deeplab v2的区别在于什么

deeplab v2也是基于encoder和decoder架构的，但是后面有连接CRF条件随机场，而deeplab v3+没有了条件随机场，deeplab v3+的亮点之处在于引入了ASPP空洞卷积模块和同步的BN

## 3.deeplab v3+损失函数CrossEntropyLoss

如果是做语义分割任务是得到一张【h,w】的语义图，那么input=【n,c,h,w】target=【n,h,w】

pytorch 损失函数需要把标签为255的忽略，有些数据集标注有白色描边（VOC 2012），不代表任何实际类别

```
nn.CrossEntropyLoss(ignore_index=255, reduction='mean')
```

## 4.实时语义分割

实时性语义分割算法进行了总结，发现当前主要有三种加速方法：1) 通过 Crop 或者 Resize 限制输入图片进而减少计算量；2) 减少网络通道数，尤其是 Early Stage；3) 还有像 ENet 类似的方法直接丢掉最后一个 Stage，如图10(a)所示。

# 域自适应

## 1.KL散度

KL 散度是一种衡量两个分布（比如两条线）之间的匹配程度的方法